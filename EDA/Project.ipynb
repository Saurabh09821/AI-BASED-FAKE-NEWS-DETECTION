{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20a20ca9-1af5-4367-bccf-110aa9c34949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in c:\\users\\hp\\sklearn-env\\lib\\site-packages (3.1.5)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\hp\\sklearn-env\\lib\\site-packages (from openpyxl) (2.0.0)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "467351a5-c50b-400f-b006-09c364b099b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\HP\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22fa986a-5153-4d32-a96e-d4b14cdfffa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------\n",
    "# Imports\n",
    "# ---------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import os\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import ngrams\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "632b8b8b-f207-46af-8ca5-655b48ab4132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset: F:/PG-DBDA-2025/Project_Upload/FAKE-NEWS-CLASSIFIER/Data_using/bharatfakenewskosh.xlsx\n",
      "Shape: (26232, 19)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Author_Name</th>\n",
       "      <th>Fact_Check_Source</th>\n",
       "      <th>Source_Type</th>\n",
       "      <th>Statement</th>\n",
       "      <th>Eng_Trans_Statement</th>\n",
       "      <th>News Body</th>\n",
       "      <th>Eng_Trans_News_Body</th>\n",
       "      <th>Media_Link</th>\n",
       "      <th>Publish_Date</th>\n",
       "      <th>Fact_Check_Link</th>\n",
       "      <th>News_Category</th>\n",
       "      <th>Language</th>\n",
       "      <th>Region</th>\n",
       "      <th>Platform</th>\n",
       "      <th>Text</th>\n",
       "      <th>Video</th>\n",
       "      <th>Image</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BFNK_1</td>\n",
       "      <td>Shinjinee Majumder</td>\n",
       "      <td>Alt News</td>\n",
       "      <td>IFCN</td>\n",
       "      <td>फ़ैक्ट-चेक: तेलंगाना में एक रिपोर्टर ने गृह मंत...</td>\n",
       "      <td>Fact-check: A reporter in Telangana stopped sp...</td>\n",
       "      <td>सोशल मीडिया पर एक वीडियो वायरल है जिसमें एक पत...</td>\n",
       "      <td>A video is viral on social media in which a jo...</td>\n",
       "      <td>https://i0.wp.com/www.altnews.in/Hindi/wp-cont...</td>\n",
       "      <td>9th July 2022</td>\n",
       "      <td>https://www.altnews.in/Hindi/fact-check-was-am...</td>\n",
       "      <td>Politics</td>\n",
       "      <td>Hindi</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BFNK_2</td>\n",
       "      <td>Kalim Ahmed</td>\n",
       "      <td>Alt News</td>\n",
       "      <td>IFCN</td>\n",
       "      <td>PM मोदी को UAE का सर्वोच्च नागरिक सम्मान मिलने...</td>\n",
       "      <td>Share by stating the old video of PM Modi's hi...</td>\n",
       "      <td>प्रधानमंत्री नरेंद्र मोदी को सोने की चेन से सम...</td>\n",
       "      <td>A video of Prime Minister Narendra Modi being ...</td>\n",
       "      <td>https://i0.wp.com/www.altnews.in/Hindi/wp-cont...</td>\n",
       "      <td>9th July 2022</td>\n",
       "      <td>https://www.altnews.in/Hindi/old-video-of-pm-m...</td>\n",
       "      <td>Politics</td>\n",
       "      <td>Hindi</td>\n",
       "      <td>National</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BFNK_3</td>\n",
       "      <td>Abhishek Kumar</td>\n",
       "      <td>Alt News</td>\n",
       "      <td>IFCN</td>\n",
       "      <td>वायरल तस्वीर में सुप्रीम कोर्ट के जज सूर्यकांत...</td>\n",
       "      <td>Supreme Court judges Suryakant and JB Pardiwal...</td>\n",
       "      <td>बीते दिनों नूपुर शर्मा ने टीवी डिबेट में पैगम्...</td>\n",
       "      <td>Recently, Nupur Sharma made an objectionable c...</td>\n",
       "      <td>https://i0.wp.com/www.altnews.in/Hindi/wp-cont...</td>\n",
       "      <td>7th July 2022</td>\n",
       "      <td>https://www.altnews.in/Hindi/false-claim-with-...</td>\n",
       "      <td>Politics</td>\n",
       "      <td>Hindi</td>\n",
       "      <td>National</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BFNK_4</td>\n",
       "      <td>Abhishek Kumar</td>\n",
       "      <td>Alt News</td>\n",
       "      <td>IFCN</td>\n",
       "      <td>मीडिया ने दी ग़लत ख़बर: कटनी में मुस्लिम सरपंच क...</td>\n",
       "      <td>Media gave wrong news: After the victory of Mu...</td>\n",
       "      <td>एक वीडियो सोशल मीडिया पर वायरल है. इसे शेयर कर...</td>\n",
       "      <td>A video is viral on social media. While sharin...</td>\n",
       "      <td>https://i0.wp.com/www.altnews.in/Hindi/wp-cont...</td>\n",
       "      <td>5th July 2022</td>\n",
       "      <td>https://www.altnews.in/Hindi/media-misreport-p...</td>\n",
       "      <td>Politics</td>\n",
       "      <td>Hindi</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BFNK_5</td>\n",
       "      <td>Kinjal</td>\n",
       "      <td>Alt News</td>\n",
       "      <td>IFCN</td>\n",
       "      <td>महिला ने राहुल गांधी को कश्मीर मुद्दे पर मोदी ...</td>\n",
       "      <td>The woman lashed out at Rahul Gandhi to oppose...</td>\n",
       "      <td>सोशल मीडिया पर राहुल गांधी का एक वीडियो वायरल ...</td>\n",
       "      <td>A video of Rahul Gandhi has gone viral on soci...</td>\n",
       "      <td>https://i0.wp.com/www.altnews.in/Hindi/wp-cont...</td>\n",
       "      <td>4th July 2022</td>\n",
       "      <td>https://www.altnews.in/Hindi/2019-video-of-wom...</td>\n",
       "      <td>Politics</td>\n",
       "      <td>Hindi</td>\n",
       "      <td>Kashmir</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id         Author_Name Fact_Check_Source Source_Type  \\\n",
       "0  BFNK_1  Shinjinee Majumder          Alt News        IFCN   \n",
       "1  BFNK_2         Kalim Ahmed          Alt News        IFCN   \n",
       "2  BFNK_3      Abhishek Kumar          Alt News        IFCN   \n",
       "3  BFNK_4      Abhishek Kumar          Alt News        IFCN   \n",
       "4  BFNK_5              Kinjal          Alt News        IFCN   \n",
       "\n",
       "                                           Statement  \\\n",
       "0  फ़ैक्ट-चेक: तेलंगाना में एक रिपोर्टर ने गृह मंत...   \n",
       "1  PM मोदी को UAE का सर्वोच्च नागरिक सम्मान मिलने...   \n",
       "2  वायरल तस्वीर में सुप्रीम कोर्ट के जज सूर्यकांत...   \n",
       "3  मीडिया ने दी ग़लत ख़बर: कटनी में मुस्लिम सरपंच क...   \n",
       "4  महिला ने राहुल गांधी को कश्मीर मुद्दे पर मोदी ...   \n",
       "\n",
       "                                 Eng_Trans_Statement  \\\n",
       "0  Fact-check: A reporter in Telangana stopped sp...   \n",
       "1  Share by stating the old video of PM Modi's hi...   \n",
       "2  Supreme Court judges Suryakant and JB Pardiwal...   \n",
       "3  Media gave wrong news: After the victory of Mu...   \n",
       "4  The woman lashed out at Rahul Gandhi to oppose...   \n",
       "\n",
       "                                           News Body  \\\n",
       "0  सोशल मीडिया पर एक वीडियो वायरल है जिसमें एक पत...   \n",
       "1  प्रधानमंत्री नरेंद्र मोदी को सोने की चेन से सम...   \n",
       "2  बीते दिनों नूपुर शर्मा ने टीवी डिबेट में पैगम्...   \n",
       "3  एक वीडियो सोशल मीडिया पर वायरल है. इसे शेयर कर...   \n",
       "4  सोशल मीडिया पर राहुल गांधी का एक वीडियो वायरल ...   \n",
       "\n",
       "                                 Eng_Trans_News_Body  \\\n",
       "0  A video is viral on social media in which a jo...   \n",
       "1  A video of Prime Minister Narendra Modi being ...   \n",
       "2  Recently, Nupur Sharma made an objectionable c...   \n",
       "3  A video is viral on social media. While sharin...   \n",
       "4  A video of Rahul Gandhi has gone viral on soci...   \n",
       "\n",
       "                                          Media_Link   Publish_Date  \\\n",
       "0  https://i0.wp.com/www.altnews.in/Hindi/wp-cont...  9th July 2022   \n",
       "1  https://i0.wp.com/www.altnews.in/Hindi/wp-cont...  9th July 2022   \n",
       "2  https://i0.wp.com/www.altnews.in/Hindi/wp-cont...  7th July 2022   \n",
       "3  https://i0.wp.com/www.altnews.in/Hindi/wp-cont...  5th July 2022   \n",
       "4  https://i0.wp.com/www.altnews.in/Hindi/wp-cont...  4th July 2022   \n",
       "\n",
       "                                     Fact_Check_Link News_Category Language  \\\n",
       "0  https://www.altnews.in/Hindi/fact-check-was-am...      Politics    Hindi   \n",
       "1  https://www.altnews.in/Hindi/old-video-of-pm-m...      Politics    Hindi   \n",
       "2  https://www.altnews.in/Hindi/false-claim-with-...      Politics    Hindi   \n",
       "3  https://www.altnews.in/Hindi/media-misreport-p...      Politics    Hindi   \n",
       "4  https://www.altnews.in/Hindi/2019-video-of-wom...      Politics    Hindi   \n",
       "\n",
       "           Region Platform Text Video Image  Label  \n",
       "0       Telangana  Twitter   no   yes    no  False  \n",
       "1        National  Twitter   no   yes    no  False  \n",
       "2        National  Twitter   no    no   yes  False  \n",
       "3  Madhya Pradesh  Twitter   no    no   yes  False  \n",
       "4         Kashmir  Twitter   no   yes    no   True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "== Basic info ==\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 26232 entries, 0 to 26231\n",
      "Data columns (total 19 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   id                   26232 non-null  object\n",
      " 1   Author_Name          26005 non-null  object\n",
      " 2   Fact_Check_Source    26232 non-null  object\n",
      " 3   Source_Type          26232 non-null  object\n",
      " 4   Statement            26232 non-null  object\n",
      " 5   Eng_Trans_Statement  26232 non-null  object\n",
      " 6   News Body            25359 non-null  object\n",
      " 7   Eng_Trans_News_Body  25360 non-null  object\n",
      " 8   Media_Link           24489 non-null  object\n",
      " 9   Publish_Date         25417 non-null  object\n",
      " 10  Fact_Check_Link      24302 non-null  object\n",
      " 11  News_Category        26216 non-null  object\n",
      " 12  Language             26232 non-null  object\n",
      " 13  Region               25525 non-null  object\n",
      " 14  Platform             26232 non-null  object\n",
      " 15  Text                 26232 non-null  object\n",
      " 16  Video                26232 non-null  object\n",
      " 17  Image                26232 non-null  object\n",
      " 18  Label                26232 non-null  bool  \n",
      "dtypes: bool(1), object(18)\n",
      "memory usage: 3.6+ MB\n",
      "None\n",
      "\n",
      "== Summary statistics (object cols) ==\n",
      "                     count unique  \\\n",
      "id                   26232  26232   \n",
      "Author_Name          26005    462   \n",
      "Fact_Check_Source    26232     19   \n",
      "Source_Type          26232      2   \n",
      "Statement            26232  24995   \n",
      "Eng_Trans_Statement  26232  24987   \n",
      "News Body            25359  24359   \n",
      "Eng_Trans_News_Body  25360  24367   \n",
      "Media_Link           24489  23080   \n",
      "Publish_Date         25417   6578   \n",
      "Fact_Check_Link      24302  23022   \n",
      "News_Category        26216     82   \n",
      "Language             26232      9   \n",
      "Region               25525    481   \n",
      "Platform             26232      8   \n",
      "Text                 26232      3   \n",
      "Video                26232      3   \n",
      "Image                26232      2   \n",
      "\n",
      "                                                                   top   freq  \n",
      "id                                                              BFNK_1      1  \n",
      "Author_Name                                                      admin   2005  \n",
      "Fact_Check_Source                                    Factcrescendo.com  10903  \n",
      "Source_Type                                                       IFCN  23826  \n",
      "Statement            Fact Check: Will you now have to pay 18% GST o...      3  \n",
      "Eng_Trans_Statement                                       Is this ...?      5  \n",
      "News Body                                             Continue Reading     22  \n",
      "Eng_Trans_News_Body                                   Continue Reading     22  \n",
      "Media_Link           https://i0.wp.com/tamil.factcrescendo.com/wp-c...     33  \n",
      "Publish_Date                                                 #########    491  \n",
      "Fact_Check_Link      https://gujarati.factcrescendo.com/archives/pa...      6  \n",
      "News_Category                                                 Politics  10436  \n",
      "Language                                                       English  10010  \n",
      "Region                                                           India  21264  \n",
      "Platform                                                       Twitter  21879  \n",
      "Text                                                                no  24429  \n",
      "Video                                                               no  14993  \n",
      "Image                                                              yes  13937  \n",
      "\n",
      "Missing value fraction per column:\n",
      " Fact_Check_Link        0.073574\n",
      "Media_Link             0.066446\n",
      "News Body              0.033280\n",
      "Eng_Trans_News_Body    0.033242\n",
      "Publish_Date           0.031069\n",
      "Region                 0.026952\n",
      "Author_Name            0.008654\n",
      "News_Category          0.000610\n",
      "id                     0.000000\n",
      "Fact_Check_Source      0.000000\n",
      "Eng_Trans_Statement    0.000000\n",
      "Statement              0.000000\n",
      "Source_Type            0.000000\n",
      "Language               0.000000\n",
      "Platform               0.000000\n",
      "Text                   0.000000\n",
      "Video                  0.000000\n",
      "Image                  0.000000\n",
      "Label                  0.000000\n",
      "dtype: float64\n",
      "\n",
      "Duplicate rows (full-row): 0\n",
      "Duplicate Statement+News Body: 858\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_14852\\3967137968.py:47: UserWarning: Parsing dates in %Y-%m-%d %H:%M:%S format when dayfirst=True was specified. Pass `dayfirst=False` or specify a format to silence this warning.\n",
      "  return pd.to_datetime(text, dayfirst=True, errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parsed publish_date sample:\n",
      "    Publish_Date publish_date_parsed\n",
      "0  9th July 2022          2022-07-09\n",
      "1  9th July 2022          2022-07-09\n",
      "2  7th July 2022          2022-07-07\n",
      "3  5th July 2022          2022-07-05\n",
      "4  4th July 2022          2022-07-04\n",
      "\n",
      "-- Top values for Author_Name --\n",
      "Author_Name\n",
      "admin               2005\n",
      "Chendur Pandian     1666\n",
      "Yogesh Karia        1320\n",
      "Pankaj Iyer         1144\n",
      "Vasuki S            1116\n",
      "Mukundan K           920\n",
      "Vikas Vyas           846\n",
      "Siddharth Sahu       664\n",
      "Saritadevi Samal     648\n",
      "Dewin Carlos         639\n",
      "Pooja Chaudhuri      622\n",
      "OpIndia Staff -      579\n",
      "Chayan Kundu         550\n",
      "Kinjal               491\n",
      "Archit Mehta         458\n",
      "Name: count, dtype: int64\n",
      "\n",
      "-- Top values for Fact_Check_Source --\n",
      "Fact_Check_Source\n",
      "Factcrescendo.com     10903\n",
      "Alt News               3343\n",
      "India Today            2495\n",
      "Boomlive.in            2272\n",
      "Youturn.in             1903\n",
      "dfrac.org               903\n",
      "OpIndia                 650\n",
      "IndiaSpend              524\n",
      "factchecker.in          524\n",
      "Vishvasnews             513\n",
      "SM Hoax Slayer          491\n",
      "The Times of India      417\n",
      "Scroll.in               324\n",
      "Newsmobile.in           200\n",
      "thip.media              199\n",
      "Name: count, dtype: int64\n",
      "\n",
      "-- Top values for Source_Type --\n",
      "Source_Type\n",
      "IFCN        23826\n",
      "Non_IFCN     2406\n",
      "Name: count, dtype: int64\n",
      "\n",
      "-- Top values for News_Category --\n",
      "News_Category\n",
      "Politics         10436\n",
      "Fact Check        4807\n",
      "Society           4565\n",
      "Society Viral      953\n",
      "Religion           778\n",
      "national           453\n",
      "Coronavirus        429\n",
      "Health             414\n",
      "International      386\n",
      "Social Viral       380\n",
      "News               353\n",
      "National           308\n",
      "international      215\n",
      "Society viral      188\n",
      "Country            156\n",
      "Name: count, dtype: int64\n",
      "\n",
      "-- Top values for Language --\n",
      "Language\n",
      "English      10010\n",
      "Tamil         4757\n",
      "Hindi         4192\n",
      "Malayalam     2723\n",
      "Gujarati      2205\n",
      "Odia          1268\n",
      "Bangla         584\n",
      "Assamese       409\n",
      "Telugu          84\n",
      "Name: count, dtype: int64\n",
      "\n",
      "-- Top values for Region --\n",
      "Region\n",
      "India            21264\n",
      "Delhi              667\n",
      "national           352\n",
      "National           230\n",
      "UP                 218\n",
      "Uttar Pradesh      173\n",
      "Tamil Nadu         161\n",
      "international       95\n",
      "Mumbai              94\n",
      "Maharashtra         88\n",
      "Kerala              80\n",
      "---                 78\n",
      "Pakistan            70\n",
      "----                68\n",
      "Rajasthan           63\n",
      "Name: count, dtype: int64\n",
      "\n",
      "-- Top values for Platform --\n",
      "Platform\n",
      "Twitter              21879\n",
      "twitter               1713\n",
      "facbook               1252\n",
      "Facebook               625\n",
      "Twitter, Facebook      315\n",
      "Facbook                313\n",
      "facebook               120\n",
      "twitter                 15\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Label distribution:\n",
      "Label\n",
      "1    15913\n",
      "0    10319\n",
      "Name: count, dtype: Int64\n",
      "\n",
      "Media columns counts (non-null true/false):\n",
      "Text:\n",
      "Text\n",
      "no     24429\n",
      "yes     1423\n",
      "no       380\n",
      "Name: count, dtype: int64\n",
      "Video:\n",
      "Video\n",
      "no     14993\n",
      "yes    10867\n",
      "no       372\n",
      "Name: count, dtype: int64\n",
      "Image:\n",
      "Image\n",
      "yes    13937\n",
      "no     12295\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Text columns found: ['Eng_Trans_Statement', 'Eng_Trans_News_Body', 'Statement', 'News Body']\n",
      "\n",
      "Text length statistics:\n",
      "                        count  non_null  mean_words  median_words  std_words  \\\n",
      "Eng_Trans_Statement  26232.0   26232.0   13.529697          13.0   4.145650   \n",
      "Eng_Trans_News_Body  26232.0   25360.0   41.437176          35.0  21.670596   \n",
      "Statement            26232.0   26232.0   12.705855          12.0   3.811573   \n",
      "News Body            26232.0   25359.0   39.451357          36.0  18.396499   \n",
      "\n",
      "                     mean_chars  \n",
      "Eng_Trans_Statement   78.479071  \n",
      "Eng_Trans_News_Body  239.075709  \n",
      "Statement             81.590615  \n",
      "News Body            270.683478  \n",
      "\n",
      "Top words for Eng_Trans_Statement:\n",
      " [('fact', 6552), ('check', 6258), ('video', 5379), ('viral', 3684), ('truth', 3397), ('old', 1993), ('learn', 1839), ('shared', 1697), ('fake', 1625), ('modi', 1454), ('bjp', 1347), ('photo', 1313), ('claim', 1277), ('india', 1241), ('really', 1227), ('news', 1204), ('claims', 1026), ('picture', 985), ('false', 951), ('police', 843), ('gandhi', 829), ('minister', 770), ('image', 770), ('government', 717), ('pm', 713)]\n",
      "Top bigrams: [(('fact', 'check'), 6152), (('of', 'the'), 3363), (('the', 'truth'), 3210), (('in', 'the'), 2655), (('video', 'of'), 2480), (('what', 'the'), 1972), (('is', 'the'), 1740), (('learn', 'what'), 1717), (('is', 'not'), 1379), (('old', 'video'), 869)]\n",
      "Top trigrams: [(('what', 'the', 'truth'), 1909), (('learn', 'what', 'the'), 1705), (('the', 'truth', 'is'), 820), (('fact', 'check', 'did'), 679), (('the', 'truth', 'of'), 640), (('what', 'is', 'the'), 585), (('truth', 'of', 'the'), 542), (('the', 'name', 'of'), 483)]\n",
      "\n",
      "Top words for Eng_Trans_News_Body:\n",
      " [('video', 11286), ('media', 11195), ('continue', 10906), ('reading', 9650), ('post', 8736), ('social', 7849), ('facebook', 7818), ('shared', 6935), ('viral', 6696), ('news', 5325), ('link', 5175), ('people', 4825), ('claim', 3889), ('india', 3868), ('information', 3658), ('minister', 3386), ('photo', 3167), ('archive', 2950), ('details', 2876), ('found', 2832), ('society', 2811), ('many', 2778), ('going', 2751), ('claimed', 2606), ('picture', 2479)]\n",
      "Top bigrams: [(('in', 'the'), 12441), (('of', 'the'), 10731), (('continue', 'reading'), 9600), (('social', 'media'), 6784), (('on', 'social'), 5484), (('that', 'the'), 4882), (('a', 'video'), 4798), (('has', 'been'), 4082), (('viral', 'on'), 3200), (('the', 'video'), 3135)]\n",
      "Top trigrams: [(('on', 'social', 'media'), 4738), (('continue', 'reading', 'a'), 2902), (('details', 'of', 'information'), 2552), (('on', 'society', 'media'), 1995), (('viral', 'on', 'social'), 1789), (('of', 'information', 'facebook'), 1766), (('is', 'going', 'viral'), 1640), (('continue', 'reading', 'the'), 1578)]\n",
      "\n",
      "Top words for Statement:\n",
      " [('fact', 6332), ('check', 6252), ('video', 2342), ('viral', 1745), ('पर', 1056), ('old', 896), ('shared', 850), ('କ', 787), ('ଣ', 784), ('fake', 715), ('modi', 672), ('claim', 610), ('india', 605), ('bjp', 593), ('pm', 574), ('claims', 537), ('factcheck', 528), ('image', 499), ('news', 460), ('photo', 436), ('falsely', 419), ('ഈ', 419), ('gandhi', 402), ('false', 400), ('और', 396)]\n",
      "Top bigrams: [(('fact', 'check'), 6232), (('check', 'fact'), 1213), (('video', 'of'), 1102), (('କ', 'ଣ'), 782), (('is', 'not'), 632), (('shared', 'as'), 629), (('check', 'did'), 460), (('ଣ', 'କ'), 435), (('old', 'video'), 397), (('viral', 'as'), 394)]\n",
      "Top trigrams: [(('fact', 'check', 'fact'), 1213), (('check', 'fact', 'check'), 1211), (('fact', 'check', 'did'), 460), (('କ', 'ଣ', 'କ'), 434), (('ଣ', 'କ', 'ଣ'), 433), (('fact', 'check', 'video'), 325), (('fact', 'check', 'old'), 284), (('fact', 'check', 'no'), 284)]\n",
      "\n",
      "Top words for News Body:\n",
      " [('continue', 10854), ('reading', 10851), ('link', 5231), ('एक', 4119), ('facebook', 3786), ('video', 3766), ('આ', 3458), ('archived', 3365), ('viral', 2901), ('media', 2881), ('पर', 2816), ('society', 2765), ('એક', 2709), ('claim', 2625), ('ഈ', 2006), ('found', 1992), ('india', 1937), ('like', 1932), ('પર', 1757), ('news', 1607), ('और', 1374), ('post', 1289), ('ଏକ', 1167), ('થઈ', 1104), ('today', 1068)]\n",
      "Top bigrams: [(('continue', 'reading'), 10841), (('archived', 'link'), 3261), (('society', 'media'), 2669), (('reading', 'facebook'), 2250), (('that', 'the'), 2048), (('on', 'society'), 2040), (('link', 'continue'), 1625), (('a', 'video'), 1593), (('in', 'the'), 1546), (('link', 'archived'), 1495)]\n",
      "Top trigrams: [(('continue', 'reading', 'facebook'), 2250), (('on', 'society', 'media'), 2000), (('link', 'continue', 'reading'), 1625), (('archived', 'link', 'continue'), 1570), (('link', 'archived', 'link'), 1459), (('આ', 'continue', 'reading'), 1176), (('found', 'that', 'the'), 1090), (('like', 'this', 'like'), 904)]\n",
      "\n",
      "Performing simple sentiment analysis on Eng_Trans_News_Body using TextBlob (polarity/subjectivity).\n",
      "       Eng_Trans_News_Body_polarity  Eng_Trans_News_Body_subjectivity\n",
      "count                  25360.000000                      25360.000000\n",
      "mean                       0.040935                          0.312045\n",
      "std                        0.200806                          0.257758\n",
      "min                       -1.000000                          0.000000\n",
      "25%                        0.000000                          0.066667\n",
      "50%                        0.000000                          0.300000\n",
      "75%                        0.129640                          0.483333\n",
      "max                        1.000000                          1.000000\n",
      "\n",
      "Category vs Label crosstab (percent by category):\n",
      " Label                 0         1\n",
      "News_Category                    \n",
      "Agriculture    0.000000  1.000000\n",
      "Analytical     0.466667  0.533333\n",
      "Attack         0.000000  1.000000\n",
      "Banking        1.000000  0.000000\n",
      "Business       0.697674  0.302326\n",
      "\n",
      "Saved correlation matrix.\n",
      "\n",
      "Saved eda_snapshot_first500.csv\n",
      "Saved eda_summary_overview.csv\n",
      "\n",
      "EDA complete. Figures saved as .png and summaries saved as CSVs in current working directory.\n"
     ]
    }
   ],
   "source": [
    "# Complete Python EDA script for your Fake News dataset\n",
    "# Replace DATA_PATH with your CSV file path if needed.\n",
    "# DEV NOTE: The path below was provided in the conversation history; replace with actual CSV path.\n",
    "DATA_PATH = \"F:/PG-DBDA-2025/Project_Upload/FAKE-NEWS-CLASSIFIER/Data_using/bharatfakenewskosh.xlsx\"  # <-- replace with \"your_dataset.csv\"\n",
    "\n",
    "# ---------------------------\n",
    "# Imports\n",
    "# ---------------------------\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import os\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import ngrams\n",
    "from textblob import TextBlob\n",
    "\n",
    "# If nltk resources not downloaded, uncomment:\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')\n",
    "\n",
    "# ---------------------------\n",
    "# Utility functions\n",
    "# ---------------------------\n",
    "def clean_publish_date(text):\n",
    "    \"\"\"\n",
    "    Normalize publish_date values like \"9th July 2022\" to a parseable date.\n",
    "    Returns pd.Timestamp or NaT.\n",
    "    \"\"\"\n",
    "    if pd.isna(text):\n",
    "        return pd.NaT\n",
    "    # Remove ordinal suffixes: 1st, 2nd, 3rd, 4th...\n",
    "    text = str(text).strip()\n",
    "    text = re.sub(r'(\\d+)(st|nd|rd|th)', r'\\1', text, flags=re.IGNORECASE)\n",
    "    # Try parsing common formats\n",
    "    for fmt in [\"%d %B %Y\", \"%d %b %Y\", \"%Y-%m-%d\", \"%d/%m/%Y\"]:\n",
    "        try:\n",
    "            return pd.to_datetime(text, format=fmt)\n",
    "        except Exception:\n",
    "            continue\n",
    "    # Fallback - try pandas parser\n",
    "    try:\n",
    "        return pd.to_datetime(text, dayfirst=True, errors='coerce')\n",
    "    except Exception:\n",
    "        return pd.NaT\n",
    "\n",
    "def text_length_stats(series):\n",
    "    \"\"\"Return DataFrame with word count, char count stats for a text series.\"\"\"\n",
    "    s = series.fillna(\"\")\n",
    "    words = s.map(lambda x: len(str(x).split()))\n",
    "    chars = s.map(lambda x: len(str(x)))\n",
    "    return pd.Series({\n",
    "        'count': s.shape[0],\n",
    "        'non_null': s.map(bool).sum(),\n",
    "        'mean_words': words.mean(),\n",
    "        'median_words': words.median(),\n",
    "        'std_words': words.std(),\n",
    "        'mean_chars': chars.mean(),\n",
    "    })\n",
    "\n",
    "def top_n_words(series, n=30, language='english'):\n",
    "    \"\"\"Return top n words excluding stopwords.\"\"\"\n",
    "    text = \" \".join(series.dropna().astype(str).tolist()).lower()\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    stops = set(stopwords.words(language))\n",
    "    words = [w for w in tokens if w.isalpha() and w not in stops]\n",
    "    return Counter(words).most_common(n)\n",
    "\n",
    "def top_ngrams(series, ngram=2, top_n=20):\n",
    "    \"\"\"Return top n n-grams from a text series.\"\"\"\n",
    "    text = \" \".join(series.dropna().astype(str).tolist()).lower()\n",
    "    tokens = [t for t in nltk.word_tokenize(text) if t.isalpha()]\n",
    "    ng = ngrams(tokens, ngram)\n",
    "    return Counter(ng).most_common(top_n)\n",
    "\n",
    "def simple_sentiment(text):\n",
    "    \"\"\"Return polarity & subjectivity using TextBlob (works on English)\"\"\"\n",
    "    if pd.isna(text) or str(text).strip()==\"\":\n",
    "        return pd.Series([np.nan, np.nan])\n",
    "    tb = TextBlob(str(text))\n",
    "    return pd.Series([tb.sentiment.polarity, tb.sentiment.subjectivity])\n",
    "\n",
    "# ---------------------------\n",
    "# Load dataset\n",
    "# ---------------------------\n",
    "print(\"Loading dataset:\", DATA_PATH)\n",
    "# attempt to load CSV; if path is image or wrong, user must replace with CSV.\n",
    "try:\n",
    "    df = pd.read_excel(DATA_PATH)\n",
    "except Exception as e:\n",
    "    print(\"Could not read as CSV. Please set DATA_PATH to your CSV file path. Error:\", e)\n",
    "    # create an empty df skeleton with columns from conversation for guidance\n",
    "    cols = [\"id\",\"Author_Name\",\"Fact_Check_Source\",\"Source_Type\",\"Statement\",\"Eng_Trans_Statement\",\n",
    "            \"News Body\",\"Eng_Trans_News_Body\",\"Media_Link\",\"Publish_Date\",\"Fact_Check_Link\",\n",
    "            \"News_Category\",\"Language\",\"Region\",\"Platform\",\"Text\",\"Video\",\"Image\",\"Label\"]\n",
    "    df = pd.DataFrame(columns=cols)\n",
    "    print(\"Created empty skeleton DataFrame with expected columns. Replace DATA_PATH and re-run.\")\n",
    "    # Stop further execution to avoid misleading outputs\n",
    "    raise SystemExit(\"Stop - set DATA_PATH to real CSV file and re-run.\")\n",
    "\n",
    "print(\"Shape:\", df.shape)\n",
    "display(df.head())\n",
    "\n",
    "# ---------------------------\n",
    "# PHASE 1: Basic overview\n",
    "# ---------------------------\n",
    "print(\"\\n== Basic info ==\")\n",
    "print(df.info())\n",
    "\n",
    "print(\"\\n== Summary statistics (object cols) ==\")\n",
    "print(df.describe(include='object').T)\n",
    "\n",
    "# Missing values per column\n",
    "miss = df.isna().mean().sort_values(ascending=False)\n",
    "print(\"\\nMissing value fraction per column:\\n\", miss)\n",
    "\n",
    "# Visual missing heatmap (save figure)\n",
    "plt.figure(figsize=(12,4))\n",
    "sns.heatmap(df.isna(), cbar=False)\n",
    "plt.title(\"Missing data heatmap\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"missing_heatmap.png\", dpi=150)\n",
    "plt.close()\n",
    "\n",
    "# Duplicates\n",
    "dup_count = df.duplicated().sum()\n",
    "print(f\"\\nDuplicate rows (full-row): {dup_count}\")\n",
    "# Check duplicates based on text fields (Statement + News Body)\n",
    "dup_text = df.duplicated(subset=[\"Statement\",\"News Body\"]).sum() if set([\"Statement\",\"News Body\"]).issubset(df.columns) else 0\n",
    "print(f\"Duplicate Statement+News Body: {dup_text}\")\n",
    "\n",
    "# ---------------------------\n",
    "# PHASE 2: Data types & conversions\n",
    "# ---------------------------\n",
    "# Lower-case columns for convenience\n",
    "df.columns = [c.strip() for c in df.columns]\n",
    "\n",
    "# Convert Label to numeric if possible\n",
    "if \"Label\" in df.columns:\n",
    "    try:\n",
    "        df[\"Label\"] = pd.to_numeric(df[\"Label\"], errors='coerce').astype('Int64')\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "# Parse Publish_Date if present\n",
    "if \"Publish_Date\" in df.columns:\n",
    "    df[\"publish_date_parsed\"] = df[\"Publish_Date\"].apply(clean_publish_date)\n",
    "    print(\"\\nParsed publish_date sample:\")\n",
    "    print(df[[\"Publish_Date\",\"publish_date_parsed\"]].head())\n",
    "    # Extract year/month/day\n",
    "    df[\"pub_year\"] = pd.DatetimeIndex(df[\"publish_date_parsed\"]).year\n",
    "    df[\"pub_month\"] = pd.DatetimeIndex(df[\"publish_date_parsed\"]).month\n",
    "    df[\"pub_dayofweek\"] = pd.DatetimeIndex(df[\"publish_date_parsed\"]).day_name()\n",
    "    # Plot monthly/yearly distribution\n",
    "    plt.figure(figsize=(10,4))\n",
    "    df[\"pub_month\"].value_counts().sort_index().plot(kind='bar')\n",
    "    plt.title(\"Count by publish month\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"publish_month_count.png\", dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "# ---------------------------\n",
    "# PHASE 3: Categorical EDA\n",
    "# ---------------------------\n",
    "cat_cols = [\"Author_Name\",\"Fact_Check_Source\",\"Source_Type\",\"News_Category\",\"Language\",\"Region\",\"Platform\"]\n",
    "cat_cols = [c for c in cat_cols if c in df.columns]\n",
    "\n",
    "for c in cat_cols:\n",
    "    print(f\"\\n-- Top values for {c} --\")\n",
    "    print(df[c].value_counts().head(15))\n",
    "    # Save barplot for top 10\n",
    "    plt.figure(figsize=(8,4))\n",
    "    df[c].value_counts().head(10).plot(kind='barh')\n",
    "    plt.title(f\"Top 10 {c}\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"top_{c}.png\", dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "# Label distribution\n",
    "if \"Label\" in df.columns:\n",
    "    print(\"\\nLabel distribution:\")\n",
    "    print(df[\"Label\"].value_counts(dropna=False))\n",
    "    plt.figure(figsize=(5,4))\n",
    "    df[\"Label\"].value_counts().plot(kind='bar')\n",
    "    plt.title(\"Label distribution (False/True or 0/1)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"label_distribution.png\", dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "# Media type counts (Text, Video, Image)\n",
    "media_cols = [c for c in [\"Text\",\"Video\",\"Image\"] if c in df.columns]\n",
    "if media_cols:\n",
    "    print(\"\\nMedia columns counts (non-null true/false):\")\n",
    "    for c in media_cols:\n",
    "        # normalize common boolean-like values\n",
    "        vc = df[c].fillna(\"no\").astype(str).str.lower().value_counts()\n",
    "        print(f\"{c}:\\n{vc}\")\n",
    "    # plot\n",
    "    plt.figure(figsize=(6,4))\n",
    "    df[media_cols].apply(lambda col: col.fillna(\"no\").astype(str).str.lower().map(lambda x: 1 if x in ['yes','true','1','y'] else 0)).sum().plot(kind='bar')\n",
    "    plt.title(\"Count of media types present\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"media_counts.png\", dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "# ---------------------------\n",
    "# PHASE 4: Text EDA\n",
    "# ---------------------------\n",
    "# Choose English-translated columns when available for NLP parts\n",
    "text_cols_candidates = [\"Eng_Trans_Statement\",\"Eng_Trans_News_Body\",\"Statement\",\"News Body\"]\n",
    "text_cols = [c for c in text_cols_candidates if c in df.columns]\n",
    "\n",
    "print(\"\\nText columns found:\", text_cols)\n",
    "\n",
    "# Basic length stats per text column\n",
    "length_stats = {}\n",
    "for c in text_cols:\n",
    "    length_stats[c] = text_length_stats(df[c])\n",
    "length_df = pd.DataFrame(length_stats).T\n",
    "print(\"\\nText length statistics:\\n\", length_df)\n",
    "length_df.to_csv(\"text_length_stats.csv\")\n",
    "\n",
    "# Compare length by Label (if Label exists)\n",
    "if \"Label\" in df.columns:\n",
    "    for c in text_cols:\n",
    "        plt.figure(figsize=(8,4))\n",
    "        df_nonnull = df[[c,\"Label\"]].dropna(subset=[c])\n",
    "        # create a words column\n",
    "        df_nonnull[\"word_count\"] = df_nonnull[c].astype(str).map(lambda x: len(x.split()))\n",
    "        sns.boxplot(x=\"Label\", y=\"word_count\", data=df_nonnull)\n",
    "        plt.title(f\"Word count by Label for {c}\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"wordcount_by_label_{c}.png\", dpi=150)\n",
    "        plt.close()\n",
    "\n",
    "# Top words and wordclouds\n",
    "stop_eng = set(stopwords.words('english'))\n",
    "for c in text_cols:\n",
    "    # Top words\n",
    "    top_words = top_n_words(df[c].astype(str).fillna(\"\"), n=50, language='english')\n",
    "    print(f\"\\nTop words for {c}:\\n\", top_words[:25])\n",
    "    # WordCloud\n",
    "    wc = WordCloud(width=800, height=400, collocations=False,\n",
    "                   stopwords=stop_eng).generate(\" \".join(df[c].dropna().astype(str).tolist()))\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.imshow(wc, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.title(f\"WordCloud: {c}\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"wordcloud_{c}.png\", dpi=150)\n",
    "    plt.close()\n",
    "    # Top bigrams/trigrams\n",
    "    print(\"Top bigrams:\", top_ngrams(df[c].astype(str).fillna(\"\"), ngram=2, top_n=20)[:10])\n",
    "    print(\"Top trigrams:\", top_ngrams(df[c].astype(str).fillna(\"\"), ngram=3, top_n=10)[:8])\n",
    "\n",
    "# ---------------------------\n",
    "# PHASE 5: Sentiment analysis (on English-translated fields)\n",
    "# ---------------------------\n",
    "# We'll use Eng_Trans_News_Body if present else Eng_Trans_Statement\n",
    "sent_col = None\n",
    "for c in [\"Eng_Trans_News_Body\",\"Eng_Trans_Statement\",\"News Body\",\"Statement\"]:\n",
    "    if c in df.columns:\n",
    "        sent_col = c\n",
    "        break\n",
    "\n",
    "if sent_col:\n",
    "    print(f\"\\nPerforming simple sentiment analysis on {sent_col} using TextBlob (polarity/subjectivity).\")\n",
    "    df[[f\"{sent_col}_polarity\", f\"{sent_col}_subjectivity\"]] = df[sent_col].fillna(\"\").astype(str).apply(simple_sentiment)\n",
    "    # Save sentiment summary\n",
    "    print(df[[f\"{sent_col}_polarity\", f\"{sent_col}_subjectivity\"]].describe())\n",
    "    df[[f\"{sent_col}_polarity\", f\"{sent_col}_subjectivity\"]].to_csv(\"sentiment_summary.csv\")\n",
    "    # Compare polarity by label if available\n",
    "    if \"Label\" in df.columns:\n",
    "        plt.figure(figsize=(8,4))\n",
    "        sns.boxplot(x=\"Label\", y=f\"{sent_col}_polarity\", data=df.dropna(subset=[f\"{sent_col}_polarity\",\"Label\"]))\n",
    "        plt.title(\"Polarity by Label\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"polarity_by_label.png\", dpi=150)\n",
    "        plt.close()\n",
    "\n",
    "# ---------------------------\n",
    "# PHASE 6: Cross-analysis & correlations\n",
    "# ---------------------------\n",
    "# Example: Label vs News_Category\n",
    "if \"Label\" in df.columns and \"News_Category\" in df.columns:\n",
    "    ct = pd.crosstab(df[\"News_Category\"], df[\"Label\"], normalize='index')\n",
    "    ct.to_csv(\"category_label_crosstab.csv\")\n",
    "    print(\"\\nCategory vs Label crosstab (percent by category):\\n\", ct.head())\n",
    "\n",
    "# Correlation between numeric-ish features: word counts, sentiment, etc.\n",
    "numeric_feats = []\n",
    "if sent_col:\n",
    "    numeric_feats += [f\"{sent_col}_polarity\", f\"{sent_col}_subjectivity\"]\n",
    "for c in text_cols:\n",
    "    if c in df.columns:\n",
    "        df[f\"{c}_wordcount\"] = df[c].fillna(\"\").astype(str).map(lambda x: len(x.split()))\n",
    "        numeric_feats.append(f\"{c}_wordcount\")\n",
    "\n",
    "# Add binary media indicators\n",
    "for m in media_cols:\n",
    "    df[f\"{m}_flag\"] = df[m].fillna(\"no\").astype(str).str.lower().map(lambda x: 1 if x in ['yes','true','1','y'] else 0)\n",
    "    numeric_feats.append(f\"{m}_flag\")\n",
    "\n",
    "# Label as numeric\n",
    "if \"Label\" in df.columns:\n",
    "    try:\n",
    "        df[\"label_numeric\"] = pd.to_numeric(df[\"Label\"], errors='coerce')\n",
    "        numeric_feats.append(\"label_numeric\")\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "if numeric_feats:\n",
    "    corr = df[numeric_feats].corr()\n",
    "    plt.figure(figsize=(8,6))\n",
    "    sns.heatmap(corr, annot=True, fmt=\".2f\", cmap=\"vlag\")\n",
    "    plt.title(\"Correlation heatmap (numeric features)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"numeric_correlation_heatmap.png\", dpi=150)\n",
    "    plt.close()\n",
    "    corr.to_csv(\"numeric_feature_correlation.csv\")\n",
    "    print(\"\\nSaved correlation matrix.\")\n",
    "\n",
    "# ---------------------------\n",
    "# PHASE 7: Save cleaned summary outputs\n",
    "# ---------------------------\n",
    "# Basic cleaned snapshot (first N rows) and a CSV for EDA results\n",
    "snapshot = df.head(500)\n",
    "snapshot.to_csv(\"eda_snapshot_first500.csv\", index=False)\n",
    "print(\"\\nSaved eda_snapshot_first500.csv\")\n",
    "\n",
    "# Summaries: missing, duplicates, top categories\n",
    "summary = {\n",
    "    \"shape\": df.shape,\n",
    "    \"missing_fraction\": miss.to_dict(),\n",
    "    \"duplicates_rowcount\": int(dup_count),\n",
    "}\n",
    "# Save summary as JSON-like CSV\n",
    "pd.Series(summary).to_csv(\"eda_summary_overview.csv\")\n",
    "print(\"Saved eda_summary_overview.csv\")\n",
    "\n",
    "print(\"\\nEDA complete. Figures saved as .png and summaries saved as CSVs in current working directory.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53425320-720a-4ccf-90d1-dfc3574f9f57",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mdf\u001b[49m.to_excel(\u001b[33m\"\u001b[39m\u001b[33mcleaned_full_dataset.xlsx\u001b[39m\u001b[33m\"\u001b[39m, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mNameError\u001b[39m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.to_excel(\"cleaned_full_dataset.xlsx\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
